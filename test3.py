import fitz  # PyMuPDF
from transformers import pipeline

# ================================
# 1. PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
# ================================
def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page in doc:
        text += page.get_text()
    return text

# ================================
# 2. ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
# ================================
def chunk_text(text, chunk_size=1500):
    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]

# ================================
# 3. è¦ç´„å‡¦ç†
# ================================
def summarize_chunks(chunks, summarizer):
    summaries = []
    for i, chunk in enumerate(chunks):
        try:
            summary = summarizer(
                chunk,
                max_length=150,   # å‡ºåŠ›ã®é•·ã•ã‚’èª¿æ•´
                min_length=40,
                do_sample=False
            )[0]["summary_text"]
            summaries.append(summary)
            print(f"âœ… Chunk {i+1}/{len(chunks)} summarized.")
        except Exception as e:
            print(f"âš ï¸ Chunk {i+1} failed: {e}")
    return summaries

def summarize_final(summaries, summarizer, chunk_size=800):
    # summaries ã®çµåˆæ–‡ã‚’ã•ã‚‰ã«å°åˆ†ã‘ã—ã¦å‡¦ç†
    text = " ".join(summaries)
    chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]
    mids = []
    for ch in chunks:
        mids.append(
            summarizer(ch, max_length=150, min_length=40, do_sample=False)[0]["summary_text"]
        )
    # ä¸­é–“ã¾ã¨ã‚ã‚’æœ€çµ‚çµåˆ
    final_input = " ".join(mids)
    final_summary = summarizer(final_input, max_length=250, min_length=80, do_sample=False)[0]["summary_text"]
    return final_summary


# ================================
# 4. ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ================================
if __name__ == "__main__":
    pdf_path = "1706.03762v7.pdf"   # ã™ã§ã«ã‚ã‚‹PDFã‚’æŒ‡å®š

    # ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
    text = extract_text_from_pdf(pdf_path)
    print(f"ğŸ“„ Extracted text length: {len(text)} characters")

    # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
    chunks = chunk_text(text, chunk_size=1500)
    print(f"ğŸ” Split into {len(chunks)} chunks")

    # Hugging Face è¦ç´„ãƒ¢ãƒ‡ãƒ«æº–å‚™
    summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

    # å„ãƒãƒ£ãƒ³ã‚¯è¦ç´„
    chunk_summaries = summarize_chunks(chunks, summarizer)

    # æœ€çµ‚ã¾ã¨ã‚è¦ç´„
    final_summary = summarize_final(chunk_summaries, summarizer)

    print("\n=== Final Summary of the Paper ===\n")
    print(final_summary)
