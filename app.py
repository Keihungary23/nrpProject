import streamlit as st

st.write("âœ… èµ·å‹•ãƒ†ã‚¹ãƒˆ: ã“ã“ã¾ã§å‹•ã„ãŸ")

import streamlit as st
from transformers import pipeline
from nlp_utils import extract_text_from_pdf, chunk_text, summarize_chunks, summarize_sections, extract_keywords, summarize_final
from pdf_utils import highlight_pdf, display_pdf

st.title("ğŸ“‘ è«–æ–‡è¦ç´„ & ãƒã‚¤ãƒ©ã‚¤ãƒˆãƒ“ãƒ¥ãƒ¼ã‚¢")

uploaded_file = st.file_uploader("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["pdf"])

if uploaded_file:
    pdf_path = "uploaded.pdf"
    with open(pdf_path, "wb") as f:
        f.write(uploaded_file.read())

    # --- è¦ç´„å‡¦ç† ---
    text = extract_text_from_pdf(pdf_path)
    chunks = chunk_text(text)
    summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
    chunk_summaries = summarize_chunks(chunks, summarizer)
    section_summaries = summarize_sections(chunk_summaries, summarizer)
    keywords_per_section = extract_keywords(section_summaries)
    final_summary = summarize_final(section_summaries, summarizer)

    st.subheader("ğŸ“ æœ€çµ‚è¦ç´„")
    st.write(final_summary)

    # --- PDFãƒã‚¤ãƒ©ã‚¤ãƒˆ & è¡¨ç¤º ---
    all_keywords = [kw for section in keywords_per_section for kw, _ in section]
    highlighted_pdf = highlight_pdf(pdf_path, all_keywords)

    st.subheader("ğŸ” ãƒã‚¤ãƒ©ã‚¤ãƒˆä»˜ãPDFãƒ“ãƒ¥ãƒ¼ã‚¢")
    display_pdf(highlighted_pdf)

    with open(highlighted_pdf, "rb") as f:
        st.download_button("â¬‡ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", f, file_name="highlighted.pdf")
